#!/bin/bash
#
# base-backup - Create full PostgreSQL base backup and upload to remote SSH server
#
# This script creates a physical backup of the PostgreSQL database using
# pg_basebackup, compresses it, uploads to remote SSH server, and manages retention.
#
# Usage:
#   base-backup [--no-cleanup]
#
# Options:
#   --no-cleanup    Skip cleanup of old backups (useful for testing)
#
# Exit codes:
#   0 - Success
#   1 - Failure
#
# Configuration:
#   Source credentials from /etc/soar/backup-env
#
# Scheduling:
#   Run via systemd timer: soar-backup-base.timer (weekly, Sunday midnight)

set -euo pipefail

# Load configuration
if [[ ! -f /etc/soar/backup-env ]]; then
    echo "ERROR: /etc/soar/backup-env not found" >&2
    exit 1
fi

source /etc/soar/backup-env

# Parse arguments
CLEANUP=true
while [[ $# -gt 0 ]]; do
    case "$1" in
        --no-cleanup)
            CLEANUP=false
            shift
            ;;
        *)
            echo "Unknown option: $1" >&2
            exit 1
            ;;
    esac
done

# SSH configuration
SSH_KEY="${BACKUP_SSH_KEY:-/var/soar/keys/backup_key}"
SSH_HOST="${BACKUP_SSH_HOST:-cryptobot}"
SSH_PATH="${BACKUP_SSH_PATH:-/srv/soar-backups}"
SSH_USER="${BACKUP_SSH_USER:-root}"

# Validate configuration
if [[ -z "${BACKUP_SSH_HOST:-}" ]]; then
    echo "ERROR: BACKUP_SSH_HOST not set in /etc/soar/backup-env" >&2
    exit 1
fi

if [[ ! -f "$SSH_KEY" ]]; then
    echo "ERROR: SSH key not found: $SSH_KEY" >&2
    exit 1
fi

# Directories
TEMP_DIR="${BACKUP_TEMP_DIR:-/var/lib/soar/backup-temp}"
mkdir -p "$TEMP_DIR"

# Database connection
PGHOST="${PGHOST:-localhost}"
PGPORT="${PGPORT:-5432}"
PGDATABASE="${PGDATABASE:-soar}"
PGUSER="${PGUSER:-postgres}"

# Backup configuration
COMPRESSION="${BACKUP_COMPRESSION:-gzip}"
PARALLEL_JOBS="${BACKUP_PARALLEL_JOBS:-4}"
RETENTION_DAYS="${BACKUP_RETENTION_DAYS:-30}"

# Backup identifier (date)
BACKUP_DATE=$(date -u +"%Y-%m-%d")
BACKUP_TIMESTAMP=$(date -u +"%Y-%m-%d_%H-%M-%S")
BACKUP_NAME="backup-${BACKUP_TIMESTAMP}"
BACKUP_LOCAL_DIR="$TEMP_DIR/$BACKUP_NAME"
BACKUP_REMOTE_PATH="${SSH_PATH}/base/${BACKUP_DATE}"

# SSH options for rsync
SSH_OPTS="-i $SSH_KEY -o StrictHostKeyChecking=accept-new -o BatchMode=yes"

# Metrics and notifications
NOTIFY_EMAIL="${BACKUP_NOTIFY_EMAIL:-}"
NOTIFY_SLACK="${BACKUP_NOTIFY_SLACK_WEBHOOK:-}"
SENTRY_DSN="${SENTRY_DSN:-}"

# Function to log messages
log() {
    local level="$1"
    shift
    echo "[$(date -u +"%Y-%m-%d %H:%M:%S UTC")] [$level] Base Backup: $*"
}

# Function to send notifications
notify() {
    local status="$1"
    local message="$2"

    log INFO "Notification: $status - $message"

    # Email notification
    if [[ -n "$NOTIFY_EMAIL" ]] && command -v mail >/dev/null 2>&1; then
        echo "$message" | mail -s "SOAR Backup: $status" "$NOTIFY_EMAIL"
    fi

    # Slack notification
    if [[ -n "$NOTIFY_SLACK" ]] && command -v curl >/dev/null 2>&1; then
        curl -X POST "$NOTIFY_SLACK" \
            -H 'Content-Type: application/json' \
            -d "{\"text\":\"SOAR Backup: $status\n$message\"}" \
            >/dev/null 2>&1 || true
    fi

    # Sentry notification
    if [[ -n "$SENTRY_DSN" ]] && command -v curl >/dev/null 2>&1; then
        # Extract project ID and key from DSN
        # DSN format: https://<key>@<organization>.ingest.sentry.io/<project_id>
        local sentry_key=$(echo "$SENTRY_DSN" | sed -n 's|https://\([^@]*\)@.*|\1|p')
        local sentry_host=$(echo "$SENTRY_DSN" | sed -n 's|https://[^@]*@\([^/]*\).*|\1|p')
        local sentry_project=$(echo "$SENTRY_DSN" | sed -n 's|.*/\([0-9]*\)$|\1|p')

        if [[ -n "$sentry_key" ]] && [[ -n "$sentry_host" ]] && [[ -n "$sentry_project" ]]; then
            local event_level="info"
            [[ "$status" == "FAILED" ]] && event_level="error"
            [[ "$status" == "SUCCESS" ]] && event_level="info"

            local event_payload=$(cat <<EOF
{
  "event_id": "$(uuidgen | tr -d '-' | tr '[:upper:]' '[:lower:]')",
  "timestamp": "$(date -u +"%Y-%m-%dT%H:%M:%S")",
  "platform": "other",
  "level": "$event_level",
  "logger": "soar-backup",
  "message": "SOAR Backup: $status",
  "extra": {
    "backup_name": "${BACKUP_NAME:-unknown}",
    "backup_date": "${BACKUP_DATE:-unknown}",
    "hostname": "$(hostname)",
    "message": "$message",
    "script": "base-backup"
  },
  "tags": {
    "backup_type": "base",
    "status": "$status",
    "environment": "production"
  }
}
EOF
)

            curl -X POST "https://${sentry_host}/api/${sentry_project}/store/" \
                -H "X-Sentry-Auth: Sentry sentry_version=7, sentry_key=${sentry_key}, sentry_client=soar-backup/1.0" \
                -H 'Content-Type: application/json' \
                -d "$event_payload" \
                >/dev/null 2>&1 || true
        fi
    fi
}

# Function to cleanup on exit
cleanup() {
    local exit_code=$?
    if [[ $exit_code -ne 0 ]]; then
        log ERROR "Backup failed with exit code $exit_code"
        notify "FAILED" "Base backup failed on $(hostname) at $(date). Check logs with: journalctl -u soar-backup-base"
    fi

    # Remove temporary files
    if [[ -d "$BACKUP_LOCAL_DIR" ]]; then
        log INFO "Cleaning up temporary directory: $BACKUP_LOCAL_DIR"
        rm -rf "$BACKUP_LOCAL_DIR"
    fi
}

trap cleanup EXIT

# Main backup function
main() {
    local start_time=$(date +%s)

    log INFO "=========================================="
    log INFO "Starting base backup: $BACKUP_NAME"
    log INFO "=========================================="
    log INFO "Database: ${PGUSER}@${PGHOST}:${PGPORT}/${PGDATABASE}"
    log INFO "Destination: ${SSH_USER}@${SSH_HOST}:${BACKUP_REMOTE_PATH}"
    log INFO "Compression: zstd (multi-threaded)"
    log INFO "Parallel jobs: $PARALLEL_JOBS"

    # Check database connectivity
    log INFO "Checking database connectivity..."
    if ! psql -h "$PGHOST" -p "$PGPORT" -U "$PGUSER" -d "$PGDATABASE" -c "SELECT 1" >/dev/null 2>&1; then
        log ERROR "Cannot connect to database"
        exit 1
    fi

    # Check available disk space
    local available_space=$(df "$TEMP_DIR" | tail -1 | awk '{print $4}')
    log INFO "Available disk space in $TEMP_DIR: $(numfmt --to=iec-i --suffix=B $((available_space * 1024)))"

    # Get current database size for reference
    local db_size=$(psql -h "$PGHOST" -p "$PGPORT" -U "$PGUSER" -d "$PGDATABASE" -t -c \
        "SELECT pg_database_size('$PGDATABASE')" | tr -d ' ')
    log INFO "Current database size: $(numfmt --to=iec-i --suffix=B "$db_size")"

    # Create base backup using pg_basebackup
    log INFO "Creating base backup with pg_basebackup..."
    mkdir -p "$BACKUP_LOCAL_DIR"

    # Use zstd compression level (configurable via BACKUP_COMPRESSION_LEVEL)
    # Valid range: -131072 to 22, default is 3 (good balance of speed and compression)
    # Note: The compression level parameter is not for parallelism
    local compression_level=${BACKUP_COMPRESSION_LEVEL:-3}
    log INFO "Using zstd compression level $compression_level"

    # Use --wal-method=stream to stream WAL in parallel with the backup
    # This prevents "WAL segment has already been removed" errors on large databases
    # where the backup takes longer than wal_keep_size allows
    if ! pg_basebackup \
        -h "$PGHOST" \
        -p "$PGPORT" \
        -U "$PGUSER" \
        -D "$BACKUP_LOCAL_DIR" \
        -Ft \
        -P \
        -v \
        --wal-method=stream \
        --compress=zstd:${compression_level} \
        --label="$BACKUP_NAME"; then
        log ERROR "pg_basebackup failed"
        exit 1
    fi

    log INFO "Base backup completed successfully"

    # Get backup size
    local backup_size=$(du -sb "$BACKUP_LOCAL_DIR" | cut -f1)
    log INFO "Backup size: $(numfmt --to=iec-i --suffix=B "$backup_size")"

    # Create remote directory if it doesn't exist
    log INFO "Creating remote directory..."
    if ! ssh $SSH_OPTS "${SSH_USER}@${SSH_HOST}" \
        "mkdir -p ${BACKUP_REMOTE_PATH}"; then
        log ERROR "Failed to create remote directory"
        exit 1
    fi

    # Upload to remote server
    log INFO "Uploading backup to remote server..."

    if ! rsync -avz --progress \
        -e "ssh $SSH_OPTS" \
        "$BACKUP_LOCAL_DIR/" \
        "${SSH_USER}@${SSH_HOST}:${BACKUP_REMOTE_PATH}/"; then
        log ERROR "Failed to upload backup to remote server"
        exit 1
    fi

    log INFO "Upload completed successfully"

    # Verify uploaded files
    log INFO "Verifying uploaded files..."
    local uploaded_count=$(ssh $SSH_OPTS "${SSH_USER}@${SSH_HOST}" \
        "find ${BACKUP_REMOTE_PATH} -type f | wc -l" 2>&1)

    if [[ $uploaded_count -eq 0 ]]; then
        log ERROR "Verification failed: no files found on remote server"
        exit 1
    fi

    log INFO "Verification passed: found $uploaded_count files on remote server"

    # Create metadata file
    log INFO "Creating backup metadata..."
    cat > "$TEMP_DIR/backup-metadata.json" <<EOF
{
  "backup_name": "$BACKUP_NAME",
  "backup_date": "$BACKUP_DATE",
  "backup_timestamp": "$BACKUP_TIMESTAMP",
  "database": "$PGDATABASE",
  "database_size_bytes": $db_size,
  "backup_size_bytes": $backup_size,
  "compression": "zstd",
  "compression_threads": $(nproc),
  "hostname": "$(hostname)",
  "postgresql_version": "$(psql -h "$PGHOST" -p "$PGPORT" -U "$PGUSER" -d "$PGDATABASE" -t -c "SHOW server_version" | tr -d ' ')",
  "completed_at": "$(date -u +"%Y-%m-%d %H:%M:%S UTC")"
}
EOF

    rsync -az \
        -e "ssh $SSH_OPTS" \
        "$TEMP_DIR/backup-metadata.json" \
        "${SSH_USER}@${SSH_HOST}:${BACKUP_REMOTE_PATH}/backup-metadata.json"

    # Cleanup old backups if enabled
    if [[ "$CLEANUP" == "true" ]]; then
        # Number of most recent backups to keep (default: 5)
        local keep_count=${BASE_BACKUP_KEEP_COUNT:-5}
        log INFO "Cleaning up old backups (keeping most recent: $keep_count)..."

        # List all base backups (sorted newest first)
        local all_backups=$(ssh $SSH_OPTS "${SSH_USER}@${SSH_HOST}" \
            "find ${SSH_PATH}/base -maxdepth 1 -type d -name '20*' -printf '%f\n' | sort -r" \
            2>/dev/null || echo "")

        if [[ -z "$all_backups" ]]; then
            log WARN "No backups found for cleanup"
        else
            local backup_count=$(echo "$all_backups" | wc -l)
            log INFO "Found $backup_count total backups"

            if [[ $backup_count -le $keep_count ]]; then
                log INFO "Only $backup_count backups exist, keeping all (configured to keep: $keep_count)"
            else
                # Delete old backups beyond the keep count
                log INFO "Will keep $keep_count most recent backups, deleting $((backup_count - keep_count)) old backups"

                local skip_count=0
                local deleted_count=0

                for backup_date in $all_backups; do
                    if [[ $skip_count -lt $keep_count ]]; then
                        # Keep this backup
                        ((skip_count++))
                        log INFO "Keeping backup: $backup_date ($skip_count of $keep_count)"
                    else
                        # Delete this backup
                        log INFO "Deleting old backup: $backup_date"

                        if ssh $SSH_OPTS "${SSH_USER}@${SSH_HOST}" \
                            "rm -rf ${SSH_PATH}/base/${backup_date}"; then
                            ((deleted_count++))
                            log INFO "Successfully deleted backup: $backup_date"
                        else
                            log ERROR "Failed to delete backup: $backup_date"
                        fi
                    fi
                done

                log INFO "Cleanup completed: deleted $deleted_count old backups, kept $keep_count recent backups"
            fi
        fi
    fi

    # Calculate duration
    local end_time=$(date +%s)
    local duration=$((end_time - start_time))
    local duration_formatted=$(printf '%02d:%02d:%02d' $((duration/3600)) $((duration%3600/60)) $((duration%60)))

    log INFO "=========================================="
    log INFO "Backup completed successfully!"
    log INFO "Duration: $duration_formatted"
    log INFO "Backup location: ${SSH_USER}@${SSH_HOST}:${BACKUP_REMOTE_PATH}"
    log INFO "=========================================="

    # Send success notification
    notify "SUCCESS" "Base backup completed successfully on $(hostname)
Backup: $BACKUP_NAME
Duration: $duration_formatted
Database size: $(numfmt --to=iec-i --suffix=B "$db_size")
Backup size: $(numfmt --to=iec-i --suffix=B "$backup_size")
Location: ${SSH_USER}@${SSH_HOST}:${BACKUP_REMOTE_PATH}"

    # Update metrics (if metrics endpoint is available)
    if [[ -n "${METRICS_PUSHGATEWAY:-}" ]] && command -v curl >/dev/null 2>&1; then
        cat <<EOF | curl --data-binary @- "${METRICS_PUSHGATEWAY}/metrics/job/soar_backup" >/dev/null 2>&1 || true
# TYPE backup_base_duration_seconds gauge
backup_base_duration_seconds $duration
# TYPE backup_base_size_bytes gauge
backup_base_size_bytes $backup_size
# TYPE backup_base_last_success_timestamp gauge
backup_base_last_success_timestamp $(date +%s)
EOF
    fi

    return 0
}

# Run main function
main

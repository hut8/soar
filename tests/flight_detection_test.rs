//! Integration test for flight detection using TestMessageSource
//!
//! This test demonstrates how to use the TestMessageSource to replay
//! real APRS message sequences and verify flight detection logic.
//!
//! Test data files are located in tests/data/flights/ and can be generated
//! using the dump-flight-messages.sh script.
use serial_test::serial;
use soar::message_sources::{RawMessageSource, TestMessageSource};

/// Example test showing how to read messages from a test file
///
/// This is a basic example showing the TestMessageSource API.
/// Real tests would process these messages through the full flight detection pipeline.
#[tokio::test]
async fn test_message_source_basic_usage() {
    // Create a simple test file
    let test_file_content = r#"2025-01-15T12:00:00.000Z FLRDDA5BA>APRS,qAS,LFNM:/120000h4821.86N/00531.07E'086/007/A=000607
2025-01-15T12:00:05.000Z FLRDDA5BA>APRS,qAS,LFNM:/120005h4821.87N/00531.08E'086/012/A=000650
2025-01-15T12:00:10.000Z FLRDDA5BA>APRS,qAS,LFNM:/120010h4821.88N/00531.09E'086/015/A=000720"#;

    // Write to a temporary file
    let temp_dir = tempfile::tempdir().unwrap();
    let test_file_path = temp_dir.path().join("test-messages.txt");
    std::fs::write(&test_file_path, test_file_content).unwrap();

    // Create a TestMessageSource
    let mut source = TestMessageSource::from_file_with_count(&test_file_path, 3)
        .await
        .unwrap();

    // Verify we can read messages
    assert_eq!(source.remaining_hint(), Some(3));

    let msg1 = source.next_message().await.unwrap();
    assert!(msg1.is_some());
    assert!(msg1.unwrap().contains("FLRDDA5BA"));
    assert_eq!(source.messages_read(), 1);

    let msg2 = source.next_message().await.unwrap();
    assert!(msg2.is_some());
    assert_eq!(source.messages_read(), 2);

    let msg3 = source.next_message().await.unwrap();
    assert!(msg3.is_some());
    assert_eq!(source.messages_read(), 3);

    // End of file
    let msg4 = source.next_message().await.unwrap();
    assert!(msg4.is_none());
}

/// Example showing how to process messages through a simple parser
///
/// This demonstrates the pattern for processing test messages.
/// Real tests would use the full PacketRouter and flight detection pipeline.
#[tokio::test]
async fn test_message_parsing_from_source() {
    let test_file_content = r#"2025-01-15T12:00:00.000Z FLRDDA5BA>APRS,qAS,LFNM:/120000h4821.86N/00531.07E'086/007/A=000607
2025-01-15T12:00:05.000Z FLRDD1234>APRS,qAS,LFNM:/120005h4821.87N/00531.08E'086/012/A=000650"#;

    let temp_dir = tempfile::tempdir().unwrap();
    let test_file_path = temp_dir.path().join("test-parsing.txt");
    std::fs::write(&test_file_path, test_file_content).unwrap();

    let mut source = TestMessageSource::from_file(&test_file_path).await.unwrap();

    let mut messages_processed = 0;

    // Process all messages
    while let Some(message) = source.next_message().await.unwrap() {
        // Extract timestamp and message parts
        let parts: Vec<&str> = message.splitn(2, ' ').collect();
        assert_eq!(parts.len(), 2, "Message should have timestamp and content");

        let timestamp_str = parts[0];
        let aprs_message = parts[1];

        // Verify timestamp format
        let timestamp = chrono::DateTime::parse_from_rfc3339(timestamp_str);
        assert!(
            timestamp.is_ok(),
            "Timestamp should be valid RFC3339: {}",
            timestamp_str
        );

        // Verify APRS message format
        assert!(
            aprs_message.contains('>') && aprs_message.contains("APRS"),
            "Should be valid APRS message format"
        );

        messages_processed += 1;
    }

    assert_eq!(messages_processed, 2);
}

// NOTE: Full integration tests with database would look like this:
//
// #[tokio::test]
// async fn test_flight_detection_timeout_resurrection() {
//     // Setup test database
//     let pool = setup_test_db().await;
//
//     // Create flight tracker and processors
//     let flight_tracker = FlightTracker::new(&pool);
//     let fix_processor = FixProcessor::new(...);
//
//     // Load test messages from a known problematic flight
//     let mut source = TestMessageSource::from_file(
//         "tests/data/flights/timeout-resurrection/abc123-should-create-new-flight.txt"
//     ).await.unwrap();
//
//     // Process all messages
//     while let Some(message) = source.next_message().await.unwrap() {
//         // Parse and process through the full pipeline
//         process_message(message, &flight_tracker, &fix_processor).await;
//     }
//
//     // Verify the correct number of flights were created
//     let flights = get_flights_for_device(&pool, device_id).await;
//     assert_eq!(flights.len(), 2, "Should create 2 separate flights");
//
//     // Verify flight timestamps and state
//     // ...
// }

/// Test case: Aircraft descended out of range while landing, then took off hours later
///
/// **Scenario:**
/// This test covers a canonical case of flight coalescing detection failure. The aircraft:
/// 1. Started descending from FL182 at -1664fpm
/// 2. Continued descending to FL034.56 at -896fpm
/// 3. Went out of range at 17:28:16 UTC (last fix while descending)
/// 4. Gap of 11.3 hours with only 32km horizontal movement
/// 5. Reappeared at 04:46:34 UTC climbing at +3392fpm at FL046.51
///
/// **Current behavior (WRONG):**
/// - Creates ONE excessively long flight spanning 11+ hours
///
/// **Expected behavior (CORRECT):**
/// - Creates TWO separate flights:
///   - Flight 1: Ends when aircraft descended out of range (landed)
///   - Flight 2: Starts when aircraft reappeared climbing (new takeoff)
///
/// **Detection criteria:**
/// - Average descent rate over last 10 fixes before gap was significant (-896fpm+)
/// - Long gap (11+ hours) with minimal horizontal movement (32km)
/// - Reappeared in climbing state (+3392fpm) only a short distance away
/// - Clear indication of landing ‚Üí ground time ‚Üí new takeoff
///
/// Flight ID: 019b4d4a-a428-76f0-8e15-1fe429f4254c
/// Environment: production
/// Messages: 1183
/// Device: ICA48683E
/// Gap: 2025-12-23T17:28:16Z to 2025-12-24T04:46:34Z (11h 18m)
/// Distance during gap: 32.29 km
/// Generated: 2025-12-24 08:00:53 UTC
#[tokio::test]
#[serial]
async fn test_descended_out_of_range_while_landing_then_took_off_hours_later() {
    use diesel::PgConnection;
    use diesel::r2d2::{ConnectionManager, Pool};
    use soar::fix_processor::FixProcessor;
    use soar::message_sources::{RawMessageSource, TestMessageSource};
    use soar::packet_processors::generic::GenericProcessor;
    use soar::raw_messages_repo::RawMessagesRepository;
    use soar::receiver_repo::ReceiverRepository;

    // ========== ARRANGE ==========

    // Set up test database
    dotenvy::dotenv().ok();
    let database_url = std::env::var("TEST_DATABASE_URL")
        .unwrap_or_else(|_| "postgresql://localhost/soar_test".to_string());
    let manager = ConnectionManager::<PgConnection>::new(database_url);
    let pool = Pool::builder()
        .build(manager)
        .expect("Failed to create pool");

    // Clean up test database before running test
    {
        use diesel::prelude::*;
        use soar::schema::{fixes, flights};
        let mut conn = pool.get().expect("Failed to get connection");
        diesel::delete(fixes::table)
            .execute(&mut conn)
            .expect("Failed to clean fixes");
        diesel::delete(flights::table)
            .execute(&mut conn)
            .expect("Failed to clean flights");
    }

    // Create repositories and processors
    let receiver_repo = ReceiverRepository::new(pool.clone());
    let raw_messages_repo = RawMessagesRepository::new(pool.clone());
    let generic_processor = GenericProcessor::new(receiver_repo, raw_messages_repo);

    // Set up elevation service for AGL calculation (required for flight creation)
    let elevation_service = soar::elevation::ElevationService::new_with_s3()
        .await
        .expect("Failed to create elevation service");

    // Enable tracing for debugging
    use tracing_subscriber::EnvFilter;
    let _ = tracing_subscriber::fmt()
        .with_env_filter(
            EnvFilter::from_default_env()
                .add_directive("soar::flight_tracker=debug".parse().unwrap()),
        )
        .try_init();

    let fix_processor = FixProcessor::new(pool.clone()).with_sync_elevation(elevation_service);

    // Load test messages
    let mut source = TestMessageSource::from_file(
        "tests/data/flights/descended-out-of-range-while-landing-then-took-off-hours-later.txt",
    )
    .await
    .expect("Failed to load test messages");

    println!("üìù Starting to process 1183 messages...");

    // ========== ACT ==========

    let mut messages_processed = 0;
    let mut first_timestamp: Option<chrono::DateTime<chrono::Utc>> = None;
    let mut last_timestamp: Option<chrono::DateTime<chrono::Utc>> = None;

    while let Some(message) = source.next_message().await.unwrap() {
        // Parse message: "YYYY-MM-DDTHH:MM:SS.SSSZ <aprs_message>"
        let (timestamp_str, aprs_message) = message
            .split_once(' ')
            .expect("Message should have timestamp");

        let received_at = chrono::DateTime::parse_from_rfc3339(timestamp_str)
            .expect("Valid RFC3339 timestamp")
            .with_timezone(&chrono::Utc);

        // Track timestamp range for later queries
        if first_timestamp.is_none() {
            first_timestamp = Some(received_at);
        }
        last_timestamp = Some(received_at);

        // Parse APRS packet
        if let Ok(packet) = ogn_parser::parse(aprs_message) {
            // First, process through generic processor to ensure aircraft/receiver exist and get context
            if let Some(context) = generic_processor
                .process_packet(&packet, aprs_message, received_at)
                .await
            {
                // Process through fix processor with the context from generic processor
                fix_processor
                    .process_aprs_packet(packet, aprs_message, context)
                    .await;
            }
        }

        messages_processed += 1;
        if messages_processed % 100 == 0 {
            println!("   Processed {} messages...", messages_processed);
        }
    }

    println!("‚úÖ Processed all {} messages", messages_processed);

    // ========== ASSERT ==========

    let first_ts = first_timestamp.expect("Should have processed at least one message");
    let last_ts = last_timestamp.expect("Should have processed at least one message");

    // Debug: Check if fixes were created
    use diesel::dsl::count_star;
    use diesel::prelude::*;
    use soar::schema::{aircraft, fixes};

    let mut conn = pool.get().expect("Failed to get database connection");

    // Filter queries by timestamp range to isolate this test from other data
    let fix_count: i64 = fixes::table
        .filter(fixes::received_at.between(first_ts, last_ts))
        .select(count_star())
        .first(&mut conn)
        .expect("Failed to count fixes");
    println!("üìä Found {} fixes in time range", fix_count);

    // Debug: Check first few fixes to understand AGL calculation
    #[allow(clippy::type_complexity)]
    let sample_fixes: Vec<(Option<i32>, Option<i32>, bool)> = fixes::table
        .filter(fixes::received_at.between(first_ts, last_ts))
        .select((
            fixes::altitude_msl_feet,
            fixes::altitude_agl_feet,
            fixes::is_active,
        ))
        .order_by(fixes::received_at.asc())
        .limit(5)
        .load(&mut conn)
        .expect("Failed to query fix details");

    println!("üìä Sample fixes (first 5):");
    for (i, (msl, agl, is_active)) in sample_fixes.iter().enumerate() {
        println!(
            "   Fix {}: MSL={:?}ft, AGL={:?}ft, is_active={}",
            i + 1,
            msl,
            agl,
            is_active
        );
    }

    // Check if AGL calculation worked - if no fixes have AGL data, skip the test
    let has_agl_data = sample_fixes.iter().any(|(_, agl, _)| agl.is_some());
    if !has_agl_data {
        eprintln!("‚ö†Ô∏è  Skipping test: No AGL data available for test location");
        eprintln!("   This test requires elevation data for accurate flight detection");
        eprintln!("   In CI, elevation tiles may not be available without AWS S3 access");
        return;
    }

    let aircraft_count: i64 = aircraft::table
        .select(count_star())
        .first(&mut conn)
        .expect("Failed to count aircraft");
    println!("üìä Found {} aircraft in database", aircraft_count);

    // Check total flights in database (not just time range)
    use soar::schema::flights;
    let total_flights: i64 = flights::table
        .select(count_star())
        .first(&mut conn)
        .expect("Failed to count flights");
    println!(
        "üìä Found {} total flights in database (all time)",
        total_flights
    );

    // If there's a flight but not in the time range, query it directly to see its timestamps
    if total_flights > 0 {
        use soar::schema::flights;
        #[allow(clippy::type_complexity)]
        let all_flights: Vec<(
            Option<chrono::DateTime<chrono::Utc>>,
            Option<chrono::DateTime<chrono::Utc>>,
            chrono::DateTime<chrono::Utc>,
        )> = flights::table
            .select((
                flights::takeoff_time,
                flights::landing_time,
                flights::last_fix_at,
            ))
            .load(&mut conn)
            .expect("Failed to query flight timestamps");

        for (i, (takeoff, landing, last_fix)) in all_flights.iter().enumerate() {
            println!(
                "   Flight {}: takeoff={:?}, landing={:?}, last_fix_at={}",
                i + 1,
                takeoff.map(|t| t.format("%Y-%m-%d %H:%M:%S").to_string()),
                landing.map(|t| t.format("%Y-%m-%d %H:%M:%S").to_string()),
                last_fix.format("%Y-%m-%d %H:%M:%S")
            );
        }
        println!(
            "   Expected range: {} to {}",
            first_ts.format("%Y-%m-%d %H:%M:%S"),
            last_ts.format("%Y-%m-%d %H:%M:%S")
        );
    }

    // CRITICAL ASSERTION: Should create TWO flights, not one
    // Note: We use total_flights count because get_flights_in_time_range() filters
    // by takeoff_time, which excludes mid-flight starts (takeoff_time=None)
    assert_eq!(
        total_flights, 2,
        "Should create 2 separate flights (one ending at landing, one starting at takeoff), not {} long flight(s). \
         Current behavior creates {} flight(s). This test documents the bug that needs fixing.",
        total_flights, total_flights
    );
}

/// Test case: Short flight during descent should be detected as spurious and deleted
///
/// **Scenario:**
/// This test verifies proper handling of a short descent sequence where an aircraft
/// descends from altitude and lands within 54 seconds. The aircraft:
/// 1. First fix: 1342ft MSL (387ft AGL) - still airborne, zero ground speed
/// 2. Descends rapidly over 11 seconds to 965ft MSL (10ft AGL) - on ground
/// 3. Remains on ground for remaining fixes (6-10ft AGL)
/// 4. Total duration: 54 seconds
/// 5. Zero ground speed throughout (paraglider drifting down)
///
/// **Expected behavior (CORRECT):**
/// 1. First fix (387ft AGL) is marked ACTIVE (above 250ft threshold)
/// 2. Flight is created when first active fix is processed
/// 3. Subsequent fixes (6-10ft AGL) are inactive - aircraft on ground
/// 4. After 5 consecutive inactive fixes, flight is completed with landing
/// 5. Flight is kept (NOT spurious - has significant altitude change 381ft)
/// 6. Final result: 1 flight with landing_time set, no takeoff_time (mid-flight start)
///
/// **Detection criteria:**
/// - Fix is "active" if: ground_speed >= 25 knots OR altitude AGL >= 250 feet
/// - Spurious flight detection removes flights < 120 seconds duration
/// - This prevents false flights from brief ground contacts or data glitches
///
/// Flight ID: 019b5853-833f-79c1-b39c-dc801104bc46
/// Environment: staging (soar_staging)
/// Messages: 6
/// Device: NAVFE4522 (Nav device)
/// Time span: 2025-12-26T01:43:46Z to 2025-12-26T01:44:40Z (~54 seconds)
/// Location: 38¬∞42.32'N 094¬∞27.59'W (same location for all fixes)
#[tokio::test]
#[serial]
async fn test_no_active_fixes_should_not_create_flight() {
    use diesel::PgConnection;
    use diesel::r2d2::{ConnectionManager, Pool};
    use soar::fix_processor::FixProcessor;
    use soar::message_sources::{RawMessageSource, TestMessageSource};
    use soar::packet_processors::generic::GenericProcessor;
    use soar::raw_messages_repo::RawMessagesRepository;
    use soar::receiver_repo::ReceiverRepository;

    // ========== ARRANGE ==========

    // Set up test database
    dotenvy::dotenv().ok();
    let database_url = std::env::var("TEST_DATABASE_URL")
        .unwrap_or_else(|_| "postgresql://localhost/soar_test".to_string());
    let manager = ConnectionManager::<PgConnection>::new(database_url);
    let pool = Pool::builder()
        .build(manager)
        .expect("Failed to create pool");

    // Clean up test database before running test
    {
        use diesel::prelude::*;
        use soar::schema::{fixes, flights};
        let mut conn = pool.get().expect("Failed to get connection");
        diesel::delete(fixes::table)
            .execute(&mut conn)
            .expect("Failed to clean fixes");
        diesel::delete(flights::table)
            .execute(&mut conn)
            .expect("Failed to clean flights");
    }

    // Create repositories and processors
    let receiver_repo = ReceiverRepository::new(pool.clone());
    let raw_messages_repo = RawMessagesRepository::new(pool.clone());
    let generic_processor = GenericProcessor::new(receiver_repo, raw_messages_repo);

    // Set up elevation service for AGL calculation (required for activity detection)
    let elevation_service = soar::elevation::ElevationService::new_with_s3()
        .await
        .expect("Failed to create elevation service");

    // Enable tracing for debugging
    use tracing_subscriber::EnvFilter;
    let _ = tracing_subscriber::fmt()
        .with_env_filter(
            EnvFilter::from_default_env()
                .add_directive("soar::flight_tracker=debug".parse().unwrap())
                .add_directive("soar::fix_processor=debug".parse().unwrap()),
        )
        .try_init();

    let fix_processor = FixProcessor::new(pool.clone()).with_sync_elevation(elevation_service);

    // Load test messages
    let mut source = TestMessageSource::from_file(
        "tests/data/flights/no-active-fixes-should-not-create-flight.txt",
    )
    .await
    .expect("Failed to load test messages");

    println!("üìù Starting to process 6 messages (all should be inactive)...");

    // ========== ACT ==========

    let mut messages_processed = 0;
    let mut first_timestamp: Option<chrono::DateTime<chrono::Utc>> = None;
    let mut last_timestamp: Option<chrono::DateTime<chrono::Utc>> = None;

    while let Some(message) = source.next_message().await.unwrap() {
        // Parse message: "YYYY-MM-DDTHH:MM:SS.SSSZ <aprs_message>"
        let (timestamp_str, aprs_message) = message
            .split_once(' ')
            .expect("Message should have timestamp");

        let received_at = chrono::DateTime::parse_from_rfc3339(timestamp_str)
            .expect("Valid RFC3339 timestamp")
            .with_timezone(&chrono::Utc);

        // Track timestamp range for later queries
        if first_timestamp.is_none() {
            first_timestamp = Some(received_at);
        }
        last_timestamp = Some(received_at);

        // Parse APRS packet
        if let Ok(packet) = ogn_parser::parse(aprs_message) {
            // First, process through generic processor to ensure aircraft/receiver exist and get context
            if let Some(context) = generic_processor
                .process_packet(&packet, aprs_message, received_at)
                .await
            {
                // Process through fix processor with the context from generic processor
                fix_processor
                    .process_aprs_packet(packet, aprs_message, context)
                    .await;
            }
        }

        messages_processed += 1;
    }

    println!("‚úÖ Processed all {} messages", messages_processed);

    // ========== ASSERT ==========

    let first_ts = first_timestamp.expect("Should have processed at least one message");
    let last_ts = last_timestamp.expect("Should have processed at least one message");

    // Debug: Check if fixes were created
    use diesel::dsl::count_star;
    use diesel::prelude::*;
    use soar::schema::{aircraft, fixes};

    let mut conn = pool.get().expect("Failed to get database connection");

    // Filter queries by timestamp range to isolate this test from other data
    let fix_count: i64 = fixes::table
        .filter(fixes::received_at.between(first_ts, last_ts))
        .select(count_star())
        .first(&mut conn)
        .expect("Failed to count fixes");
    println!("üìä Found {} fixes in time range", fix_count);

    // Debug: Check AGL values to understand why is_active isn't set correctly
    #[allow(clippy::type_complexity)]
    let fix_details: Vec<(Option<i32>, Option<i32>, bool)> = fixes::table
        .filter(fixes::received_at.between(first_ts, last_ts))
        .select((
            fixes::altitude_msl_feet,
            fixes::altitude_agl_feet,
            fixes::is_active,
        ))
        .order_by(fixes::received_at.asc())
        .load(&mut conn)
        .expect("Failed to query fix details");

    for (i, (msl, agl, is_active)) in fix_details.iter().enumerate() {
        println!(
            "   Fix {}: MSL={:?}ft, AGL={:?}ft, is_active={}",
            i + 1,
            msl,
            agl,
            is_active
        );
    }

    // Check if AGL calculation worked - if no fixes have AGL data, skip the test
    // This can happen in CI when elevation tiles aren't available for this location
    let has_agl_data = fix_details.iter().any(|(_, agl, _)| agl.is_some());
    if !has_agl_data {
        eprintln!("‚ö†Ô∏è  Skipping test: No AGL data available for test location");
        eprintln!("   This test requires elevation tile for 38¬∞42'N, 094¬∞27'W");
        eprintln!("   In CI, this may not be available without AWS S3 access");
        return;
    }

    // Verify active fix count
    // The first fix has AGL=387ft which is >= 250ft, so it should be marked active
    // The remaining 5 fixes have AGL=6-10ft, so they should be inactive
    // Filter by timestamp range to only count fixes from this test run
    let active_fix_count: i64 = fixes::table
        .filter(fixes::is_active.eq(true))
        .filter(fixes::received_at.between(first_ts, last_ts))
        .select(count_star())
        .first(&mut conn)
        .expect("Failed to count active fixes");
    println!(
        "üìä Found {} active fixes in time range (expected 1 - first fix at 387ft AGL)",
        active_fix_count
    );

    assert_eq!(
        active_fix_count, 1,
        "First fix should be active (AGL=387ft >= 250ft threshold), remaining 5 should be inactive"
    );

    let aircraft_count: i64 = aircraft::table
        .select(count_star())
        .first(&mut conn)
        .expect("Failed to count aircraft");
    println!("üìä Found {} aircraft in database", aircraft_count);

    // Check total flights in database (not just time range)
    use soar::schema::flights;
    let total_flights: i64 = flights::table
        .select(count_star())
        .first(&mut conn)
        .expect("Failed to count flights");
    println!(
        "üìä Found {} total flights in database (all time)",
        total_flights
    );

    // If there's a flight, show its details for debugging
    if total_flights > 0 {
        use soar::schema::flights;
        #[allow(clippy::type_complexity)]
        let all_flights: Vec<(
            Option<chrono::DateTime<chrono::Utc>>,
            Option<chrono::DateTime<chrono::Utc>>,
            chrono::DateTime<chrono::Utc>,
        )> = flights::table
            .select((
                flights::takeoff_time,
                flights::landing_time,
                flights::last_fix_at,
            ))
            .load(&mut conn)
            .expect("Failed to query flight timestamps");

        for (i, (takeoff, landing, last_fix)) in all_flights.iter().enumerate() {
            println!(
                "   Flight {}: takeoff={:?}, landing={:?}, last_fix_at={}",
                i + 1,
                takeoff.map(|t| t.format("%Y-%m-%d %H:%M:%S").to_string()),
                landing.map(|t| t.format("%Y-%m-%d %H:%M:%S").to_string()),
                last_fix.format("%Y-%m-%d %H:%M:%S")
            );
        }
        println!(
            "   Expected range: {} to {}",
            first_ts.format("%Y-%m-%d %H:%M:%S"),
            last_ts.format("%Y-%m-%d %H:%M:%S")
        );

        // Query and display the fix activity status
        #[allow(clippy::type_complexity)]
        let fix_details: Vec<(
            chrono::DateTime<chrono::Utc>,
            Option<i32>,
            Option<i32>,
            Option<f32>,
            bool,
        )> = fixes::table
            .select((
                fixes::timestamp,
                fixes::altitude_msl_feet,
                fixes::altitude_agl_feet,
                fixes::ground_speed_knots,
                fixes::is_active,
            ))
            .order(fixes::timestamp.asc())
            .load(&mut conn)
            .expect("Failed to query fix details");

        println!("   Fix details:");
        for (ts, msl, agl, speed, active) in fix_details {
            println!(
                "     {}: MSL={:?}ft, AGL={:?}ft, Speed={:?}kt, Active={}",
                ts.format("%H:%M:%S"),
                msl,
                agl,
                speed,
                active
            );
        }
    }

    // CRITICAL ASSERTION: Should create ONE flight (not deleted as spurious due to altitude change)
    // The flight is created for the first active fix and kept because it has significant altitude change
    assert_eq!(
        total_flights, 1,
        "Should have 1 flight. Flight was created for active fix (387ft AGL), completed with landing, \
         and kept (not spurious) due to 381ft altitude change. Found {} flight(s).",
        total_flights
    );
}
